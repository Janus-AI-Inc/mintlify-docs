---
title: "Janus Python SDK"
description: "Automatically evaluate your AI systems at scale with simulation"
---

## Evaluate AI Agents in Days, not Months

The end-to-end simulation engine that auto-generates comprehensive benchmarks 
so you can ship production-ready agents 10x faster.

What you get:

- Auto-generate 10,000+ scenarios in hours (zero annotation)

- Comprehensive distribution coverage (95%+ of realistic cases)

- One platform for technical and nontechnical teams (SDK + UI)

- Export RLHF-ready training data from every test run

<Card
  title="Quick Start"
  icon="rocket"
  href="/quickstart"
  horizontal
>
  Get up and running with your first AI agent test in under 5 minutes.
</Card>

## What Janus Does

<Columns cols={2}>
  <Card
    title="Simulation Environments"
    icon="flask"
    href="/concepts/agent-testing"
  >
    Evaluate your agents with 10,000+ scenarios from 10-15 seed examples, each simulating different personalities, intents, and edge cases.
  </Card>
  <Card
    title="Customized Judges & Metrics"
    icon="chart-line"
    href="/concepts/evaluation"
  >
    Define any metric that matters - from hard rules (compliance, accuracy) 
  to qualitative KPIs (politeness, satisfaction) - with LLM-as-judge 
  scoring calibrated to your domain.
  </Card>
  <Card
    title="Data Export & Fine-Tuning"
    icon="route"
    href="/concepts/webapp-setup"
  >
    Export every simulation as RLHF-ready training data for fine-tuning. Includes full trajectories, reward signals, and edge cases - ready for GPT clustering or model improvement.
  </Card>
  <Card
    title="Hallucination Detection & Knowledge Base Cross-Checking"
    icon="shield-check"
    href="/concepts/evaluation"
  >
    Upload your docs, PDFs, or KBs - Janus validates agent responses against ground truth.
  </Card>

</Columns>

## Key Features

### **Automated Simulations**
Run multiple conversation simulations with different personas to test your AI agent's behavior across various scenarios.

```python
await janus.run_simulations(
    num_simulations=10,
    max_turns=5,
    target_agent=lambda: MyAgent().chat,
    api_key="your_janus_api_key"
)
```

### **Function Call Tracing**
Automatically trace function calls with the `@track` decorator or manually trace external tools and APIs.

```python
from janus_sdk import track, start_tool_event, finish_tool_event

@track
def analyze_data(data: dict) -> dict:
    return analysis_result

# Manual tracing for external tools
handle = start_tool_event("database_query", "SELECT * FROM users")
result = query_database()
finish_tool_event(handle, result)
```

### **Rule-Based Evaluation**
Define custom rules to evaluate your agent's responses and detect issues like hallucinations or policy violations. Specify rules directly in the SDK or more robustly and specifically in the Janus webapp.

```python
rules = [
    "The agent should never provide medical advice",
    "The agent should cite sources when making claims",
    "The agent should stay within the conversation context"
]
```

### **Framework Integration**
Works seamlessly with popular frameworks like LangChain through custom callbacks.

```python
from janus_sdk import JanusLangChainCallback

agent_executor = AgentExecutor(
    agent=agent,
    tools=[weather_tool],
    callbacks=[JanusLangChainCallback()]
)
```

## Use Cases

Janus Python SDK is designed to help you test and evaluate AI applications across various domains:

### **Customer Support & Service**
Test customer service agents (chat, voice, or workflow-based) to ensure they provide accurate, helpful responses while maintaining brand voice and compliance standards.

### **Healthcare & Medical**
Validate medical AI applications for accuracy, safety, and compliance with healthcare regulations. Test responses to medical queries, medication information, and treatment recommendations across any interaction format.

### **Finance & Banking**
Ensure financial AI advisors and agents follow strict compliance rules, provide accurate financial information, and maintain security protocols regardless of how users interact with them.

### **Education & Training**
Test educational AI tutors and learning assistants for accuracy, appropriate content levels, and educational effectiveness across different subjects, age groups, and interaction methods.

### **E-commerce & Retail**
Validate product recommendation engines, shopping assistants, and customer service agents for accuracy, helpfulness, and conversion optimization through any user interface.

### **Legal & Compliance**
Test legal AI assistants for accuracy, compliance with legal standards, and appropriate disclaimers and limitations across all interaction channels.

<Info>
**Tip:** Janus helps you define domain-specific rules and test scenarios that match your industry requirements and compliance needs.
</Info>

## Get Started

<Steps>
<Step title="Install the SDK">
  Install Janus Python SDK using pip:
  
  ```bash
  pip install janus-python-sdk
  ```
  
  <Check>
  Verify installation by importing the SDK: `import janus_sdk`
  </Check>
</Step>

<Step title="Get an API Key">
  Contact the Janus team at [team@withjanus.com](mailto:team@withjanus.com) to get your API key and login credentials for accessing the Janus platform.
  
  <Warning>
  Keep your API key secure and never commit it to version control.
  </Warning>
</Step>

<Step title="Run Your First Test">
  Follow our <a href="/quickstart">quickstart guide</a> to test your first AI agent in under 5 minutes.
</Step>
</Steps>


