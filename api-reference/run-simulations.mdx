---
title: "run_simulations"
description: "Run multiple AI agent simulations with automated testing and evaluation"
---

## run_simulations

Run multiple AI agent simulations to test and evaluate your agent's performance across various conversation scenarios.

### Function Signature

```python
def run_simulations(
    *,
    target_agent: Callable[[], Callable[[str], Awaitable[str] | str]],
    api_key: str,
    num_simulations: int,
    max_turns: int,
    base_url: Optional[str] = None,
    context: Optional[str] = None,
    goal: Optional[str] = None,
    rules: Optional[Sequence[str]] = None,
    persona_kwargs: Optional[Dict[str, str]] = None,
) -> List[dict]
```

### Parameters

<ParamField name="target_agent" type="Callable" required>
Factory function that creates agent instances. Must return a callable that takes a string prompt and returns a string response (sync or async).
</ParamField>

<ParamField name="api_key" type="string" required>
Your Janus API key for authentication. Contact [team@withjanus.com](mailto:team@withjanus.com) to get your API key.
</ParamField>

<ParamField name="num_simulations" type="integer" required>
Number of conversation simulations to run. Recommended: 10-100 for comprehensive testing.
</ParamField>

<ParamField name="max_turns" type="integer" required>
Maximum number of conversation turns per simulation. Recommended: 5-10 for most use cases.
</ParamField>

<ParamField name="base_url" type="string" default="https://api.withjanus.com">
Base URL for the Janus API. Only change for custom deployments.
</ParamField>

<ParamField name="context" type="string" default="You are testing an AI agent in a conversational scenario.">
Context provided to the conversation personas. Sets the scenario for testing.
</ParamField>

<ParamField name="goal" type="string" default="Evaluate the agent's performance through natural conversation.">
Goal for the conversation personas. Defines what they're trying to achieve.
</ParamField>

<ParamField name="rules" type="List[string]" optional>
List of rules to evaluate agent responses. Used for rule-based judgment scoring.
</ParamField>

<ParamField name="persona_kwargs" type="Dict[string, string]" optional>
Additional keyword arguments passed to conversation personas. Allows customization of persona behavior.
</ParamField>

### Returns

<ResponseField name="results" type="List[dict]" required>
List of simulation results, one for each conversation simulation.
</ResponseField>

### Basic Usage

```python
import asyncio
import janus_sdk as janus

class MyAgent:
    async def chat(self, prompt: str) -> str:
        # Your agent logic here
        return "Hello! I'm your AI assistant."

async def main():
    results = await janus.run_simulations(
        num_simulations=10,
        max_turns=5,
        target_agent=lambda: MyAgent().chat,
        api_key="your_janus_api_key"  # Contact team@withjanus.com to get your API key
    )
    
    print(f"Completed {len(results)} simulations")

asyncio.run(main())
```

### Advanced Usage with Rules

```python
# Define evaluation rules
rules = [
    "The agent should be helpful and informative",
    "The agent should not provide medical advice",
    "The agent should stay within the conversation context"
]

results = await janus.run_simulations(
    num_simulations=20,
    max_turns=8,
    target_agent=lambda: MyAgent().chat,
    api_key="your_janus_api_key",  # Contact team@withjanus.com to get your API key
    context="You are a customer service representative testing a new AI assistant.",
    goal="Test the AI assistant's ability to handle customer inquiries professionally.",
    rules=rules
)
```

### Custom Context and Personas

```python
# Customize the testing scenario
results = await janus.run_simulations(
    num_simulations=15,
    max_turns=6,
    target_agent=lambda: MyAgent().chat,
    api_key="your_janus_api_key",  # Contact team@withjanus.com to get your API key
    context="You are a technical support specialist helping users with software issues.",
    goal="Evaluate the AI assistant's technical knowledge and problem-solving abilities.",
    persona_kwargs={
        "expertise_level": "intermediate",
        "communication_style": "professional"
    }
)
```

### Response Format

Each simulation result contains:

<ResponseField name="simulation_id" type="string" required>
Unique identifier for the simulation.
</ResponseField>

<ResponseField name="status" type="string" required>
Status of the simulation: "completed", "failed", or "timeout".
</ResponseField>

<ResponseField name="conversation" type="List[dict]" required>
Full conversation history with timestamps and participant information.
</ResponseField>

<ResponseField name="metrics" type="dict" optional>
Performance metrics including response times, token usage, and evaluation scores.
</ResponseField>

<ResponseField name="evaluation" type="dict" optional>
Rule-based evaluation results and judgment scores.
</ResponseField>

### Example Response

```json
{
  "simulation_id": "sim_abc123",
  "status": "completed",
  "conversation": [
    {
      "turn": 1,
      "participant": "user",
      "message": "Hello, can you help me with a technical issue?",
      "timestamp": "2024-01-15T10:30:00Z"
    },
    {
      "turn": 2,
      "participant": "agent",
      "message": "Of course! I'd be happy to help. What technical issue are you experiencing?",
      "timestamp": "2024-01-15T10:30:05Z"
    }
  ],
  "metrics": {
    "total_turns": 2,
    "avg_response_time_ms": 2500,
    "total_tokens": 45
  },
  "evaluation": {
    "rule_scores": {
      "helpful_and_informative": 0.9,
      "no_medical_advice": 1.0,
      "context_appropriate": 0.8
    },
    "overall_score": 0.9
  }
}
```

### Error Handling

The function handles various error scenarios:

<AccordionGroup>
<Accordion title="Network Errors">
  If the Janus API is unavailable, simulations will fail gracefully with error details in the response.
</Accordion>

<Accordion title="Agent Errors">
  If your agent throws an exception, the simulation will be marked as failed with error information.
</Accordion>

<Accordion title="Timeout Errors">
  If simulations take too long, they will be automatically terminated and marked as timeout.
</Accordion>
</AccordionGroup>

### Performance Considerations

<Tip>
- Start with `num_simulations=10` for quick testing
- Use `max_turns=5` for faster results
- Increase simulation count gradually as you optimize your agent
- Monitor API rate limits for large-scale testing
</Tip>

<Warning>
Running many simulations can be resource-intensive. Monitor your system resources and API usage.
</Warning>

### Related Functions

<CardGroup cols={2}>
<Card title="arun_simulations" icon="code" href="/api-reference/arun-simulations">
  Async version of run_simulations for advanced use cases
</Card>

<Card title="track decorator" icon="route" href="/api-reference/track-decorator">
  Automatically trace function calls in your agent
</Card>
</CardGroup> 